# Generation Models 

This directory contains the model definitions and scripts to preprocess data, train, evaluate and compare the models.

Please take a look at the README file in the **models** folder for more details on how to train and evaluate these models.

You can download the pretrained speaker models from [this link](https://uva.data.surfsara.nl/index.php/s/iiactCdOHfl3s2N) (best run per model type indicated below).

The naming conventions in the paper are different from what we had used in the code:

**base:** Ref (best seed 1)
speaker/saved_models/model_speaker_base_1_bert_2020-05-26-13-28-38.pkl

**histatt:** ReRef (best seed 42)
speaker/saved_models/model_speaker_hist_att_42_bert_2020-05-21-15-13-22.pkl

**copy:** Copy (best seed 1)
speaker/saved_models/model_speaker_COPY_copy_1_bert_2020-05-25-20-3-58.pkl

To preprocess the data for the Ref and ReRef models, you should run speaker/utils/new_dataset_processor.py. For the Copy model, please run speaker/utils/new_dataset_processor_copy.py.

In the generated_outputs_model_all_* files, we provide the utterances generated by all the models with 5 different seeds. To inspect the generated utterances only by the best model per model type that we used in our analyses, please take a look at the generated_outputs_model_selected_* files.

Abbreviations in the generated output files: 

I: Image set (visual context of the speaker)

T: Target image for which we will generate a new utterance

U: Next utterance (utterance to be generated)

P: Previous utterance (if exists, otherwise &lt;nohs&gt;)

A: Actual previous utterance (without &lt;unk&gt; tokens)

R: Set of utterances referring to the same image in the game

H42: utterance generated by the model trained with seed 42

H1: utterance generated by the model trained with seed 1

H2: utterance generated by the model trained with seed 2

H3: utterance generated by the model trained with seed 3

H4: utterance generated by the model trained with seed 4

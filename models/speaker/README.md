# Generation Models 

This directory contains the model definitions and scripts to preprocess data, train, evaluate and compare the models.

Please take a look at the README file in the **models** folder for more details on how to train and evaluate these models.

Processed data and pretrained models will be available later.

In the generated_outputs_model_all_* files, we provide the utterances generated by all the models with 5 different seeds. To inspect the generated utterances only by the best model per model type that we used in our analyses, please take a look at the generated_outputs_model_selected_* files.

Abbreviations in the generated output files: 

I: Image set (visual context of the speaker)

T: Target image for which we will generate a new utterance

U: Next utterance (utterance to be generated)

P: Previous utterance (if exists, otherwise <nohs>)

A: Actual previous utterance (without <unk> tokens)

R: Set of utterances referring to the same image in the game

H42: utterance generated by the model trained with seed 42

H1: utterance generated by the model trained with seed 1

H2: utterance generated by the model trained with seed 2

H3: utterance generated by the model trained with seed 3

H4: utterance generated by the model trained with seed 4
